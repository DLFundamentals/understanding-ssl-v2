Dataset: cifar100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169M/169M [00:03<00:00, 48.1MB/s]
Setting up Decoupled Contrastive Learning
Setting up Negatives-only Supervised Contrastive Learning
Setting up Supervised Contrastive Learning
[GPU 0] Training epoch 0...
  4%|â–ˆâ–ˆâ–ˆâ–‹                                                                                    | 2/48 [00:05<02:02,  2.66s/it]/home/priyadarsimishra/understanding_ssl_v2/utils/optimizer.py:142: UserWarning: This overload of add_ is deprecated:
ðŸ§® Accumulative batch loss at batch idx 0 for DCL model: 8.524026870727539
ðŸ§® Accumulative batch loss at batch idx 0 for NSCL model: 8.513345718383789
ðŸ§® Accumulative batch loss at batch idx 0 for SCL model: 9.217639923095703
ðŸ§® Accumulative batch loss at batch idx 1 for DCL model: 17.084898948669434
ðŸ§® Accumulative batch loss at batch idx 1 for NSCL model: 17.062524795532227
ðŸ§® Accumulative batch loss at batch idx 1 for SCL model: 18.431638717651367
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1691.)
  next_v.mul_(momentum).add_(scaled_lr, grad)
ðŸ§® Accumulative batch loss at batch idx 2 for DCL model: 25.68936252593994
ðŸ§® Accumulative batch loss at batch idx 2 for NSCL model: 25.655189514160156
ðŸ§® Accumulative batch loss at batch idx 2 for SCL model: 27.59814453125
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                               | 13/48 [00:18<00:42,  1.21s/it]
ðŸ§® Accumulative batch loss at batch idx 3 for DCL model: 34.36762523651123
ðŸ§® Accumulative batch loss at batch idx 3 for NSCL model: 34.322174072265625
ðŸ§® Accumulative batch loss at batch idx 3 for SCL model: 36.58476448059082
ðŸ§® Accumulative batch loss at batch idx 4 for DCL model: 42.865400314331055
ðŸ§® Accumulative batch loss at batch idx 4 for NSCL model: 42.80800151824951
ðŸ§® Accumulative batch loss at batch idx 4 for SCL model: 45.236351013183594
ðŸ§® Accumulative batch loss at batch idx 5 for DCL model: 51.3608283996582
ðŸ§® Accumulative batch loss at batch idx 5 for NSCL model: 51.288514137268066
ðŸ§® Accumulative batch loss at batch idx 5 for SCL model: 53.89112854003906
ðŸ§® Accumulative batch loss at batch idx 6 for DCL model: 59.611931800842285
ðŸ§® Accumulative batch loss at batch idx 6 for NSCL model: 59.5374698638916
ðŸ§® Accumulative batch loss at batch idx 6 for SCL model: 62.30910110473633
ðŸ§® Accumulative batch loss at batch idx 7 for DCL model: 67.8405704498291
ðŸ§® Accumulative batch loss at batch idx 7 for NSCL model: 67.7546558380127
ðŸ§® Accumulative batch loss at batch idx 7 for SCL model: 70.68513011932373
ðŸ§® Accumulative batch loss at batch idx 8 for DCL model: 75.97205448150635
ðŸ§® Accumulative batch loss at batch idx 8 for NSCL model: 75.98028564453125
ðŸ§® Accumulative batch loss at batch idx 8 for SCL model: 78.98066997528076
ðŸ§® Accumulative batch loss at batch idx 9 for DCL model: 84.07201671600342
ðŸ§® Accumulative batch loss at batch idx 9 for NSCL model: 84.07127571105957
ðŸ§® Accumulative batch loss at batch idx 9 for SCL model: 87.21887493133545
ðŸ§® Accumulative batch loss at batch idx 10 for DCL model: 92.01261472702026
ðŸ§® Accumulative batch loss at batch idx 10 for NSCL model: 92.03973865509033
ðŸ§® Accumulative batch loss at batch idx 10 for SCL model: 95.40718650817871
ðŸ§® Accumulative batch loss at batch idx 11 for DCL model: 99.98725128173828
ðŸ§® Accumulative batch loss at batch idx 11 for NSCL model: 100.02527284622192
ðŸ§® Accumulative batch loss at batch idx 11 for SCL model: 103.57616901397705
ðŸ§® Accumulative batch loss at batch idx 12 for DCL model: 107.99726676940918
ðŸ§® Accumulative batch loss at batch idx 12 for NSCL model: 108.05594682693481
ðŸ§® Accumulative batch loss at batch idx 12 for SCL model: 111.7391357421875
ðŸ§® Accumulative batch loss at batch idx 13 for DCL model: 115.92646741867065
ðŸ§® Accumulative batch loss at batch idx 13 for NSCL model: 115.9918999671936
ðŸ§® Accumulative batch loss at batch idx 13 for SCL model: 119.89054203033447
ðŸ§® Accumulative batch loss at batch idx 14 for DCL model: 123.84125471115112
ðŸ§® Accumulative batch loss at batch idx 14 for NSCL model: 123.89155340194702
ðŸ§® Accumulative batch loss at batch idx 14 for SCL model: 128.0252571105957
ðŸ§® Accumulative batch loss at batch idx 15 for DCL model: 131.68160486221313
ðŸ§® Accumulative batch loss at batch idx 15 for NSCL model: 131.74675369262695
ðŸ§® Accumulative batch loss at batch idx 15 for SCL model: 136.14841842651367
ðŸ§® Accumulative batch loss at batch idx 16 for DCL model: 139.58309936523438
ðŸ§® Accumulative batch loss at batch idx 16 for NSCL model: 139.5785994529724
ðŸ§® Accumulative batch loss at batch idx 16 for SCL model: 144.24116325378418
ðŸ§® Accumulative batch loss at batch idx 17 for DCL model: 147.48860692977905
ðŸ§® Accumulative batch loss at batch idx 17 for NSCL model: 147.4542031288147
ðŸ§® Accumulative batch loss at batch idx 17 for SCL model: 152.34492588043213
ðŸ§® Accumulative batch loss at batch idx 18 for DCL model: 155.35251760482788
ðŸ§® Accumulative batch loss at batch idx 18 for NSCL model: 155.3060917854309
ðŸ§® Accumulative batch loss at batch idx 18 for SCL model: 160.41985511779785
ðŸ§® Accumulative batch loss at batch idx 19 for DCL model: 163.23159790039062
ðŸ§® Accumulative batch loss at batch idx 19 for NSCL model: 163.15648221969604
ðŸ§® Accumulative batch loss at batch idx 19 for SCL model: 168.52502536773682
ðŸ§® Accumulative batch loss at batch idx 20 for DCL model: 171.0854892730713
ðŸ§® Accumulative batch loss at batch idx 20 for NSCL model: 171.02013778686523
ðŸ§® Accumulative batch loss at batch idx 20 for SCL model: 176.61096286773682
ðŸ§® Accumulative batch loss at batch idx 21 for DCL model: 178.95263719558716
ðŸ§® Accumulative batch loss at batch idx 21 for NSCL model: 178.8490743637085
ðŸ§® Accumulative batch loss at batch idx 21 for SCL model: 184.6938247680664
ðŸ§® Accumulative batch loss at batch idx 22 for DCL model: 186.79154443740845
ðŸ§® Accumulative batch loss at batch idx 22 for NSCL model: 186.7236566543579
ðŸ§® Accumulative batch loss at batch idx 22 for SCL model: 192.7553653717041
ðŸ§® Accumulative batch loss at batch idx 23 for DCL model: 194.65990114212036
ðŸ§® Accumulative batch loss at batch idx 23 for NSCL model: 194.5266571044922
ðŸ§® Accumulative batch loss at batch idx 23 for SCL model: 200.82419109344482
ðŸ§® Accumulative batch loss at batch idx 24 for DCL model: 202.46736192703247
ðŸ§® Accumulative batch loss at batch idx 24 for NSCL model: 202.26200485229492
ðŸ§® Accumulative batch loss at batch idx 24 for SCL model: 208.88818454742432
ðŸ§® Accumulative batch loss at batch idx 25 for DCL model: 210.2775001525879
ðŸ§® Accumulative batch loss at batch idx 25 for NSCL model: 210.04203033447266
ðŸ§® Accumulative batch loss at batch idx 25 for SCL model: 216.95070934295654
ðŸ§® Accumulative batch loss at batch idx 26 for DCL model: 218.0830397605896
ðŸ§® Accumulative batch loss at batch idx 26 for NSCL model: 217.8163080215454
ðŸ§® Accumulative batch loss at batch idx 26 for SCL model: 225.0112428665161
ðŸ§® Accumulative batch loss at batch idx 27 for DCL model: 225.88074827194214
ðŸ§® Accumulative batch loss at batch idx 27 for NSCL model: 225.61061096191406
ðŸ§® Accumulative batch loss at batch idx 27 for SCL model: 233.06238842010498
ðŸ§® Accumulative batch loss at batch idx 28 for DCL model: 233.67447328567505
ðŸ§® Accumulative batch loss at batch idx 28 for NSCL model: 233.3601040840149
ðŸ§® Accumulative batch loss at batch idx 28 for SCL model: 241.11486721038818
ðŸ§® Accumulative batch loss at batch idx 29 for DCL model: 241.44654989242554
ðŸ§® Accumulative batch loss at batch idx 29 for NSCL model: 241.1366744041443
ðŸ§® Accumulative batch loss at batch idx 29 for SCL model: 249.17808055877686
ðŸ§® Accumulative batch loss at batch idx 30 for DCL model: 249.22110509872437
ðŸ§® Accumulative batch loss at batch idx 30 for NSCL model: 248.96178150177002
ðŸ§® Accumulative batch loss at batch idx 30 for SCL model: 257.2199602127075
ðŸ§® Accumulative batch loss at batch idx 31 for DCL model: 256.94933462142944
ðŸ§® Accumulative batch loss at batch idx 31 for NSCL model: 256.7057809829712
ðŸ§® Accumulative batch loss at batch idx 31 for SCL model: 265.2784729003906
ðŸ§® Accumulative batch loss at batch idx 32 for DCL model: 264.7164788246155
ðŸ§® Accumulative batch loss at batch idx 32 for NSCL model: 264.3907470703125
ðŸ§® Accumulative batch loss at batch idx 32 for SCL model: 273.32909774780273
ðŸ§® Accumulative batch loss at batch idx 33 for DCL model: 272.4765934944153
ðŸ§® Accumulative batch loss at batch idx 33 for NSCL model: 272.1465792655945
ðŸ§® Accumulative batch loss at batch idx 33 for SCL model: 281.3713264465332
ðŸ§® Accumulative batch loss at batch idx 34 for DCL model: 280.1716618537903
ðŸ§® Accumulative batch loss at batch idx 34 for NSCL model: 279.8278155326843
ðŸ§® Accumulative batch loss at batch idx 34 for SCL model: 289.40625762939453
ðŸ§® Accumulative batch loss at batch idx 35 for DCL model: 287.93302631378174
ðŸ§® Accumulative batch loss at batch idx 35 for NSCL model: 287.5673041343689
ðŸ§® Accumulative batch loss at batch idx 35 for SCL model: 297.4571304321289
ðŸ§® Accumulative batch loss at batch idx 36 for DCL model: 295.7064208984375
ðŸ§® Accumulative batch loss at batch idx 36 for NSCL model: 295.32099533081055
ðŸ§® Accumulative batch loss at batch idx 36 for SCL model: 305.49635219573975
ðŸ§® Accumulative batch loss at batch idx 37 for DCL model: 303.48511600494385
ðŸ§® Accumulative batch loss at batch idx 37 for NSCL model: 303.0941243171692
ðŸ§® Accumulative batch loss at batch idx 37 for SCL model: 313.53712940216064
ðŸ§® Accumulative batch loss at batch idx 38 for DCL model: 311.28914070129395
ðŸ§® Accumulative batch loss at batch idx 38 for NSCL model: 310.8528513908386
ðŸ§® Accumulative batch loss at batch idx 38 for SCL model: 321.5706195831299
ðŸ§® Accumulative batch loss at batch idx 39 for DCL model: 318.99274921417236
ðŸ§® Accumulative batch loss at batch idx 39 for NSCL model: 318.5097665786743
ðŸ§® Accumulative batch loss at batch idx 39 for SCL model: 329.60778045654297
ðŸ§® Accumulative batch loss at batch idx 40 for DCL model: 326.6789655685425
ðŸ§® Accumulative batch loss at batch idx 40 for NSCL model: 326.18891429901123
ðŸ§® Accumulative batch loss at batch idx 40 for SCL model: 337.63983154296875
ðŸ§® Accumulative batch loss at batch idx 41 for DCL model: 334.41886711120605
ðŸ§® Accumulative batch loss at batch idx 41 for NSCL model: 333.9601306915283
ðŸ§® Accumulative batch loss at batch idx 41 for SCL model: 345.6790428161621
ðŸ§® Accumulative batch loss at batch idx 42 for DCL model: 342.0928268432617
ðŸ§® Accumulative batch loss at batch idx 42 for NSCL model: 341.6841859817505
ðŸ§® Accumulative batch loss at batch idx 42 for SCL model: 353.71384620666504
ðŸ§® Accumulative batch loss at batch idx 43 for DCL model: 349.7275447845459
ðŸ§® Accumulative batch loss at batch idx 43 for NSCL model: 349.3434491157532
ðŸ§® Accumulative batch loss at batch idx 43 for SCL model: 361.74166679382324
ðŸ§® Accumulative batch loss at batch idx 44 for DCL model: 357.43338108062744
ðŸ§® Accumulative batch loss at batch idx 44 for NSCL model: 357.0150375366211
ðŸ§® Accumulative batch loss at batch idx 44 for SCL model: 369.77547550201416
ðŸ§® Accumulative batch loss at batch idx 45 for DCL model: 365.0850405693054
ðŸ§® Accumulative batch loss at batch idx 45 for NSCL model: 364.62573432922363
ðŸ§® Accumulative batch loss at batch idx 45 for SCL model: 377.8086700439453
ðŸ§® Accumulative batch loss at batch idx 46 for DCL model: 372.7556953430176
ðŸ§® Accumulative batch loss at batch idx 46 for NSCL model: 372.26130294799805
ðŸ§® Accumulative batch loss at batch idx 46 for SCL model: 385.80624294281006
ðŸ§® Accumulative batch loss at batch idx 47 for DCL model: 380.445517539978
ðŸ§® Accumulative batch loss at batch idx 47 for NSCL model: 379.93345737457275
ðŸ§® Accumulative batch loss at batch idx 47 for SCL model: 393.81782627105713
Saved dcl model to checkpoints/cifar100_parallel//dcl/snapshot_0.pth at epoch 0
Saved nscl model to checkpoints/cifar100_parallel//nscl/snapshot_0.pth at epoch 0
Saved scl model to checkpoints/cifar100_parallel//scl/snapshot_0.pth at epoch 0
Saved all models at epoch 0
DCL Loss per epoch: 7.925948282082875
NSCL Loss per epoch: 7.915280361970265
SCL Loss per epoch: 8.20453804731369

=== Starting Evaluation ===
perform_rsa: False
len(self.models_config): 3
models_config keys: ['dcl', 'nscl', 'scl']
Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.87it/s]
Extracted features for dcl: torch.Size([10000, 2048])
Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.51it/s]
Evaluation accuracies: [0.05609999969601631]
CDNV: 20.680740356445312, Dir-CDNV: 7.614536285400391
Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.49it/s]
Extracted features for nscl: torch.Size([10000, 2048])
Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.33it/s]
Evaluation accuracies: [0.05339999869465828]
CDNV: 20.537137985229492, Dir-CDNV: 7.662957191467285
Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.34it/s]
Extracted features for scl: torch.Size([10000, 2048])
Extracting Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  5.36it/s]
Evaluation accuracies: [0.0681999996304512]
CDNV: 19.81829833984375, Dir-CDNV: 6.650873184204102
[GPU 0] Training epoch 1...
  0%|                                                                                                | 0/48 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/priyadarsimishra/understanding_ssl_v2/scripts/parallel_dcl_nscl_train_simclr.py", line 474, in <module>
    trainer.train(epochs)
  File "/home/priyadarsimishra/understanding_ssl_v2/scripts/parallel_dcl_nscl_train_simclr.py", line 173, in train
    losses_per_epoch = self._run_epoch(epoch)
  File "/home/priyadarsimishra/understanding_ssl_v2/scripts/parallel_dcl_nscl_train_simclr.py", line 148, in _run_epoch
    for i, batch in enumerate(tqdm(self.train_loader)):
  File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
  File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1492, in _next_data
    idx, data = self._get_data()
  File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1444, in _get_data
    success, data = self._try_get_data()
  File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1285, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/threading.py", line 324, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/priyadarsimishra/understanding_ssl_v2/scripts/parallel_dcl_nscl_train_simclr.py", line 474, in <module>
[rank0]:     trainer.train(epochs)
[rank0]:   File "/home/priyadarsimishra/understanding_ssl_v2/scripts/parallel_dcl_nscl_train_simclr.py", line 173, in train
[rank0]:     losses_per_epoch = self._run_epoch(epoch)
[rank0]:   File "/home/priyadarsimishra/understanding_ssl_v2/scripts/parallel_dcl_nscl_train_simclr.py", line 148, in _run_epoch
[rank0]:     for i, batch in enumerate(tqdm(self.train_loader)):
[rank0]:   File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
[rank0]:     for obj in iterable:
[rank0]:   File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1492, in _next_data
[rank0]:     idx, data = self._get_data()
[rank0]:   File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1444, in _get_data
[rank0]:     success, data = self._try_get_data()
[rank0]:   File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1285, in _try_get_data
[rank0]:     data = self._data_queue.get(timeout=timeout)
[rank0]:   File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/queue.py", line 180, in get
[rank0]:     self.not_empty.wait(remaining)
[rank0]:   File "/home/priyadarsimishra/anaconda3/envs/contrastive/lib/python3.10/threading.py", line 324, in wait
[rank0]:     gotit = waiter.acquire(True, timeout)
[rank0]: KeyboardInterrupt
